{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference Examples\n",
    "# 1 Foundations\n",
    "Julian Hsu\n",
    "Date Made: 5 Aug 2021 \n",
    "\n",
    "### Table of Contents with Navigation Links\n",
    "* [Write Causal Models](#Section1)\n",
    "* [Simulate Data](#Section2)\n",
    "* [Bootstrapping Examples](#Section3)\n",
    "* [Bootstrapping Examples - unconfoundedness violation](#Section4)\n",
    "* [Bootstrapping Examples - overlap violation](#Section5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.discrete.conditional_models import ConditionalLogit\n",
    "\n",
    "from IPython.display import display    \n",
    "\n",
    "\n",
    "import scipy.stats \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section1'></a>\n",
    "\n",
    "## Write Causal Models\n",
    "Write several functions here for estimate HTE. Each model _must_ do datasplitting.\n",
    "These functions will do a lot of predictions, so try to standardize the prediction models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stnomics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "\n",
    "## Bring in Simulated Data\n",
    "Pretend we've never seen this data before, and do balance checks between treatment and control \n",
    "\n",
    "For fun, use the Friedman function: https://www.sfu.ca/~ssurjano/fried.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    N = 2000\n",
    "    \n",
    "    cov = [[1.00, 0.08, 0.05, 0.05],\n",
    "           [0.08, 1.00,-0.08,-0.02],\n",
    "           [0.05,-0.08, 1.00,-0.10],\n",
    "           [0.05,-0.02,-0.10, 1.00]]\n",
    "    cov = np.eye(4)\n",
    "    X = np.random.multivariate_normal(np.zeros(4), cov,N)\n",
    "    x1,x2,x3,x4= X[:,0],X[:,1],X[:,2],X[:,3]\n",
    "\n",
    "    treatment_latent = 2*np.sin( np.pi * x4 * x3) + 10*(x2-0.5)**2 - 10*x1\n",
    "    m,s = np.average(treatment_latent), np.std(treatment_latent)\n",
    "\n",
    "    treatment_latent = (treatment_latent - m) / s\n",
    "    \n",
    "    random_t = np.random.normal(0,1,N)\n",
    "    \n",
    "    treatment_latent += random_t\n",
    "    \n",
    "    treatment = np.array( np.exp(treatment_latent) / (1+ np.exp(treatment_latent)) > np.random.uniform(0,1,N) ).astype(np.int32)\n",
    "\n",
    "#     Y = 100 +0.5*x1 - 6*x2 + -2*x4*x1 + 0.5*x1*x2 - 7*(x3+1)**(0.5) + 8/(0.5+x3+x4)\n",
    "    Y = 100 + 10*np.sin( np.pi * x1 * x2) + 20*(x3-0.5)**2 - 10*x4\n",
    "#     GT = np.std(Y)\n",
    "    random_y = np.random.normal(0,1,N)\n",
    "\n",
    "    GT = 5\n",
    "    Y += np.random.normal(1,2,N)\n",
    "    Y += GT*(treatment==1) \n",
    "    \n",
    "    df_est = pd.DataFrame({'x1':x1, 'x2':x2,'x3':x3,'x4':x4,'treatment':treatment, 'Y':Y, 'GT':GT} )\n",
    "    df_est['x1_2'] = df_est['x1'].pow(2)\n",
    "    df_est['x2_2'] = df_est['x2'].pow(2)\n",
    "    df_est['x3_2'] = df_est['x3'].pow(2)\n",
    "    df_est['x4_2'] = df_est['x4'].pow(2)    \n",
    "    return df_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>treatment</th>\n",
       "      <th>Y</th>\n",
       "      <th>GT</th>\n",
       "      <th>x1_2</th>\n",
       "      <th>x2_2</th>\n",
       "      <th>x3_2</th>\n",
       "      <th>x4_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.313283</td>\n",
       "      <td>-0.489695</td>\n",
       "      <td>0.563628</td>\n",
       "      <td>-0.324982</td>\n",
       "      <td>1</td>\n",
       "      <td>105.700209</td>\n",
       "      <td>5</td>\n",
       "      <td>0.098146</td>\n",
       "      <td>0.239801</td>\n",
       "      <td>0.317676</td>\n",
       "      <td>0.105613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.347911</td>\n",
       "      <td>0.829529</td>\n",
       "      <td>0.863875</td>\n",
       "      <td>-0.082179</td>\n",
       "      <td>1</td>\n",
       "      <td>102.593495</td>\n",
       "      <td>5</td>\n",
       "      <td>0.121042</td>\n",
       "      <td>0.688119</td>\n",
       "      <td>0.746279</td>\n",
       "      <td>0.006753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.674069</td>\n",
       "      <td>1.074357</td>\n",
       "      <td>0.852527</td>\n",
       "      <td>0.582977</td>\n",
       "      <td>0</td>\n",
       "      <td>105.036677</td>\n",
       "      <td>5</td>\n",
       "      <td>2.802507</td>\n",
       "      <td>1.154242</td>\n",
       "      <td>0.726802</td>\n",
       "      <td>0.339862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288611</td>\n",
       "      <td>-0.335995</td>\n",
       "      <td>-1.054658</td>\n",
       "      <td>-0.091539</td>\n",
       "      <td>0</td>\n",
       "      <td>144.336512</td>\n",
       "      <td>5</td>\n",
       "      <td>0.083296</td>\n",
       "      <td>0.112893</td>\n",
       "      <td>1.112303</td>\n",
       "      <td>0.008379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.972706</td>\n",
       "      <td>0.119425</td>\n",
       "      <td>-1.156609</td>\n",
       "      <td>-0.030407</td>\n",
       "      <td>0</td>\n",
       "      <td>152.401670</td>\n",
       "      <td>5</td>\n",
       "      <td>0.946158</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>1.337744</td>\n",
       "      <td>0.000925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>-0.644172</td>\n",
       "      <td>-0.381519</td>\n",
       "      <td>2.104919</td>\n",
       "      <td>-0.124986</td>\n",
       "      <td>0</td>\n",
       "      <td>158.054612</td>\n",
       "      <td>5</td>\n",
       "      <td>0.414957</td>\n",
       "      <td>0.145557</td>\n",
       "      <td>4.430683</td>\n",
       "      <td>0.015621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.018871</td>\n",
       "      <td>-1.890406</td>\n",
       "      <td>0.717081</td>\n",
       "      <td>1.377236</td>\n",
       "      <td>1</td>\n",
       "      <td>96.820982</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>3.573634</td>\n",
       "      <td>0.514205</td>\n",
       "      <td>1.896778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.782518</td>\n",
       "      <td>-0.175322</td>\n",
       "      <td>-0.079507</td>\n",
       "      <td>0.643935</td>\n",
       "      <td>1</td>\n",
       "      <td>97.958290</td>\n",
       "      <td>5</td>\n",
       "      <td>0.612335</td>\n",
       "      <td>0.030738</td>\n",
       "      <td>0.006321</td>\n",
       "      <td>0.414652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-1.698061</td>\n",
       "      <td>-0.853848</td>\n",
       "      <td>0.383134</td>\n",
       "      <td>1.211971</td>\n",
       "      <td>1</td>\n",
       "      <td>81.896919</td>\n",
       "      <td>5</td>\n",
       "      <td>2.883411</td>\n",
       "      <td>0.729056</td>\n",
       "      <td>0.146792</td>\n",
       "      <td>1.468875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.783112</td>\n",
       "      <td>0.654464</td>\n",
       "      <td>0.445458</td>\n",
       "      <td>-0.876325</td>\n",
       "      <td>1</td>\n",
       "      <td>119.786695</td>\n",
       "      <td>5</td>\n",
       "      <td>3.179490</td>\n",
       "      <td>0.428324</td>\n",
       "      <td>0.198432</td>\n",
       "      <td>0.767946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2        x3        x4  treatment           Y  GT  \\\n",
       "0     0.313283 -0.489695  0.563628 -0.324982          1  105.700209   5   \n",
       "1    -0.347911  0.829529  0.863875 -0.082179          1  102.593495   5   \n",
       "2    -1.674069  1.074357  0.852527  0.582977          0  105.036677   5   \n",
       "3     0.288611 -0.335995 -1.054658 -0.091539          0  144.336512   5   \n",
       "4    -0.972706  0.119425 -1.156609 -0.030407          0  152.401670   5   \n",
       "...        ...       ...       ...       ...        ...         ...  ..   \n",
       "1995 -0.644172 -0.381519  2.104919 -0.124986          0  158.054612   5   \n",
       "1996 -0.018871 -1.890406  0.717081  1.377236          1   96.820982   5   \n",
       "1997  0.782518 -0.175322 -0.079507  0.643935          1   97.958290   5   \n",
       "1998 -1.698061 -0.853848  0.383134  1.211971          1   81.896919   5   \n",
       "1999 -1.783112  0.654464  0.445458 -0.876325          1  119.786695   5   \n",
       "\n",
       "          x1_2      x2_2      x3_2      x4_2  \n",
       "0     0.098146  0.239801  0.317676  0.105613  \n",
       "1     0.121042  0.688119  0.746279  0.006753  \n",
       "2     2.802507  1.154242  0.726802  0.339862  \n",
       "3     0.083296  0.112893  1.112303  0.008379  \n",
       "4     0.946158  0.014262  1.337744  0.000925  \n",
       "...        ...       ...       ...       ...  \n",
       "1995  0.414957  0.145557  4.430683  0.015621  \n",
       "1996  0.000356  3.573634  0.514205  1.896778  \n",
       "1997  0.612335  0.030738  0.006321  0.414652  \n",
       "1998  2.883411  0.729056  0.146792  1.468875  \n",
       "1999  3.179490  0.428324  0.198432  0.767946  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_max_iter = 500\n",
    "## treatment prediction models\n",
    "t_models = {}\n",
    "t_models['LogitCV'] = LogisticRegressionCV(cv=5, random_state=27, n_jobs=-1)\n",
    "t_models['logit'] = LogisticRegression(penalty='l2',solver='lbfgs', C=1, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L1_C2'] = LogisticRegression(penalty='l1',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L2_C5'] = LogisticRegression(penalty='l2',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['rf_md10'] = RandomForestClassifier(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "t_models['rf_md3'] = RandomForestClassifier(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "t_models['nn'] = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1,max_iter=model_max_iter)\n",
    "## outcome prediction models\n",
    "y_models = {}\n",
    "y_models['LassoCV'] = LassoCV(cv=5, n_jobs=-1,  random_state=27)\n",
    "y_models['ols'] = LinearRegression()\n",
    "y_models['lasso_a2'] = Lasso(alpha=2,max_iter=model_max_iter)\n",
    "y_models['ridge_a2'] = Ridge(alpha=2,max_iter=model_max_iter)\n",
    "y_models['rf_md10'] = RandomForestRegressor(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "y_models['rf_md3'] = RandomForestRegressor(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "y_models['nn'] = MLPRegressor(alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1, max_iter=model_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_splits = 4\n",
    "aux_dictionary = {'n_bins': 2, 'n_trees':2, 'max_depth':2, \n",
    "                  'upper':0.999, 'lower':0.001,\n",
    "                  'bootstrapreps':100,\n",
    "                  'subsample_ratio':0.5}\n",
    "bootstrap_number = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "\n",
    "feature_list = [x for x in df.columns if 'x' in x]\n",
    "\n",
    "ols = st.ate.ols_vanilla(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "pbin = st.ate.propbinning(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "plm = st.ate.dml.dml_plm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "irm = st.ate.dml.dml_irm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "df['splits'] = np.random.choice(n_data_splits, len(df), replace=True)\n",
    "df = df.sort_values(by='splits')    \n",
    "\n",
    "## Predict Treatment\n",
    "that = st.predict_treatment_indicator(df, 'splits', n_data_splits, feature_list,'treatment',t_models['LogitCV'])\n",
    "df['that'] = that\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "ax.hist(df.loc[df.treatment==1]['that'], density=False, facecolor='g', alpha=0.25)\n",
    "ax.hist(df.loc[df.treatment==0]['that'], density=False, facecolor='b', alpha=0.25)\n",
    "control_range_to_remove = np.percentile(df.loc[df.treatment==1]['that'], q= 50) , np.percentile(df.loc[df.treatment==1]['that'], q= 99)\n",
    "print(control_range_to_remove)\n",
    "\n",
    "df = df.loc[ (df.treatment==1) | ( (df.that.between(control_range_to_remove[0],control_range_to_remove[1])==False) & (df.treatment==0) )   ]\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "ax.hist(df.loc[df.treatment==1]['that'], density=False, facecolor='g', alpha=0.25)\n",
    "ax.hist(df.loc[df.treatment==0]['that'], density=False, facecolor='b', alpha=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section4'></a>\n",
    "\n",
    "## Bootstrapping\n",
    "* Bootstrap results using random datasets when all three assumptions are satisfied.\n",
    "* Bootstrap results when the unconfoundedness assumption is violated. Do this by removing one fot the features from training.\n",
    "* Bootstrap results when the overlap assumption is violated. Do this by removing control observations with propensities near the median treatment obervation propensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_x = []\n",
    "pbin_x= []\n",
    "plm_x = []\n",
    "irm_x = []\n",
    "ipw_x = []\n",
    "\n",
    "ols_x_unconf = []\n",
    "pbin_x_unconf= []\n",
    "plm_x_unconf = []\n",
    "irm_x_unconf = []\n",
    "ipw_x_unconf = []\n",
    "\n",
    "ols_x_overlap = []\n",
    "pbin_x_overlap= []\n",
    "plm_x_overlap = []\n",
    "irm_x_overlap = []\n",
    "ipw_x_overlap = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(bootstrap_number):\n",
    "    df = generate_data()\n",
    "    \n",
    "    feature_list = [x for x in df.columns if 'x' in x]\n",
    "    \n",
    "    feature_list_ab = [x for x in feature_list if '3' not in x and '4' not in x]\n",
    "    \n",
    "    ## Regular \n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "    ols_x.append(ols['ATE TE'])\n",
    "    pbin_x.append(pbin['ATE TE'])\n",
    "    plm_x.append(plm['ATE TE'])\n",
    "    irm_x.append(irm['ATE TE'])    \n",
    "    ipw_x.append(ip['ATE TE'])   \n",
    "    \n",
    "    ## When unconfoundedness assumption is not true\n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "    ols_x_unconf.append(ols['ATE TE'])\n",
    "    pbin_x_unconf.append(pbin['ATE TE'])\n",
    "    plm_x_unconf.append(plm['ATE TE'])\n",
    "    irm_x_unconf.append(irm['ATE TE'])    \n",
    "    ipw_x_unconf.append(ip['ATE TE'])        \n",
    "\n",
    "\n",
    "    ## When overlap condition is not true\n",
    "    df['splits'] = np.random.choice(n_data_splits, len(df), replace=True)\n",
    "    df = df.sort_values(by='splits')    \n",
    "    ## Predict Treatment\n",
    "    that = st.predict_treatment_indicator(df, 'splits', n_data_splits, feature_list,'treatment',t_models['LogitCV'])\n",
    "    df['that'] = that    \n",
    "    control_range_to_remove = np.percentile(df.loc[df.treatment==1]['that'], q= 50) , np.percentile(df.loc[df.treatment==1]['that'], q= 99)\n",
    "    df = df.loc[ (df.treatment==1) | ( (df.that.between(control_range_to_remove[0],control_range_to_remove[1])==False) & (df.treatment==0) )   ]\n",
    "\n",
    "\n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "\n",
    "    ols_x_overlap.append(ols['ATE TE'])\n",
    "    pbin_x_overlap.append(pbin['ATE TE'])\n",
    "    plm_x_overlap.append(plm['ATE TE'])\n",
    "    irm_x_overlap.append(irm['ATE TE'])    \n",
    "    ipw_x_overlap.append(ip['ATE TE'])        \n",
    "\n",
    "ols_x = np.array(ols_x) - 5\n",
    "pbin_x = np.array(pbin_x) - 5\n",
    "plm_x = np.array(plm_x) - 5\n",
    "irm_x = np.array(irm_x) - 5\n",
    "ipw_x = np.array(ipw_x) - 5\n",
    "\n",
    "ols_x_unconf = np.array(ols_x_unconf) - 5\n",
    "pbin_x_unconf = np.array(pbin_x_unconf) - 5\n",
    "plm_x_unconf = np.array(plm_x_unconf) - 5\n",
    "irm_x_unconf = np.array(irm_x_unconf) - 5\n",
    "ipw_x_unconf = np.array(ipw_x_unconf) - 5    \n",
    "\n",
    "ols_x_overlap = np.array(ols_x_overlap) - 5\n",
    "pbin_x_overlap = np.array(pbin_x_overlap) - 5\n",
    "plm_x_overlap = np.array(plm_x_overlap) - 5\n",
    "irm_x_overlap = np.array(irm_x_overlap) - 5\n",
    "ipw_x_overlap = np.array(ipw_x_overlap) - 5    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_avg_med_iqr(x):\n",
    "    avg = np.average(x)\n",
    "    p50 = np.percentile(x, 50)\n",
    "    p25 = np.percentile(x, 25)\n",
    "    p75 = np.percentile(x, 75)    \n",
    "    print('AVG: {0:5.2f}   MED: {1:5.2f}   IQR: [{2:5.3f}, {3:5.2f}]'.format(avg, p50, p25, p75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bias when all assumptions are met')\n",
    "print_avg_med_iqr(ols_x)    \n",
    "print_avg_med_iqr(pbin_x)    \n",
    "print_avg_med_iqr(plm_x)    \n",
    "print_avg_med_iqr(irm_x)    \n",
    "print_avg_med_iqr(ipw_x)    \n",
    "\n",
    "print('')\n",
    "print('Bias when unconfoundedness is not met')\n",
    "print_avg_med_iqr(ols_x_unconf) \n",
    "print_avg_med_iqr(pbin_x_unconf)    \n",
    "print_avg_med_iqr(plm_x_unconf)    \n",
    "print_avg_med_iqr(irm_x_unconf)    \n",
    "print_avg_med_iqr(ipw_x_unconf)    \n",
    "\n",
    "print('')\n",
    "print('Bias when overlap is not met')\n",
    "print_avg_med_iqr(ols_x_overlap)    \n",
    "print_avg_med_iqr(pbin_x_overlap)    \n",
    "print_avg_med_iqr(plm_x_overlap)    \n",
    "print_avg_med_iqr(irm_x_overlap)    \n",
    "print_avg_med_iqr(ipw_x_overlap[~np.isnan(ipw_x_overlap)])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section5'></a>\n",
    "\n",
    "## Prediction vs Causal\n",
    "Let's compare the estimated treatment effects $\\hat{Y}(W=1) - \\hat{Y}(W=0) $ among ML models. Let's use the treatment effect of multiple features.\n",
    "\n",
    "We expect to find evidence of regularization bias. As demonstrated in **Figure 1** of Chernozhukov et al., \"*Double/Debiased Machine Learning for Treatment and Structural Parameters*\" (https://arxiv.org/pdf/1608.00060.pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data(WDim=2,\n",
    "             TE = [1,1],\n",
    "             N = 50):\n",
    "    corr = False\n",
    "    if corr==False:\n",
    "        pass\n",
    "    else:\n",
    "        x = np.random.uniform(0,1,N)\n",
    "        \n",
    "    for r in range(WDim+1):\n",
    "        if corr==False:\n",
    "            W = np.random.randint(0,2, N)     \n",
    "        else: \n",
    "            x1 = np.random.uniform(-1,1,N)                \n",
    "            W = ( ( np.exp(x + x1) / (1+ np.exp(x+x1)) ) > np.random.uniform(0.45,0.55) ).astype(float)\n",
    "        if r ==0:\n",
    "            Y = TE[r]*W + np.random.normal(0,1, N)\n",
    "            data_dict = {'W1':W}\n",
    "        else:\n",
    "            Y = TE[r]*W\n",
    "            data_dict['W'+str(r)] = W\n",
    "    data_dict['Y'] = Y\n",
    "    return pd.DataFrame(data=data_dict, index=np.arange(N))\n",
    "#     if corr==False:\n",
    "#         W1 = np.random.randint(0,2, N) \n",
    "#         W2 = np.random.randint(0,2, N)     \n",
    "#     else:\n",
    "#         x = np.random.uniform(0,1,N)\n",
    "#         x1 = np.random.uniform(-1,1,N)\n",
    "#         x2 = np.random.uniform(-1,1,N)        \n",
    "#         W1 = ( ( np.exp(x + x1) / (1+ np.exp(x+x1)) ) > np.random.uniform(0.45,0.55) ).astype(float)\n",
    "#         W2 = ( ( np.exp(x + x2) / (1+ np.exp(x+x2)) ) > np.random.uniform(0.45,0.55) ).astype(float)        \n",
    "\n",
    "\n",
    "#     Y = TE[0]*W1 + TE[1]*W2 + np.random.normal(0,1, N)\n",
    "#     return pd.DataFrame(data={'Y':Y, 'W1':W1, 'W2': W2}, index=np.arange(N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_te(X, WDim, func):\n",
    "    trained = func.fit(X[[x for x in X.columns if 'W' in x]], X['Y'])\n",
    "    te_output = {}\n",
    "    for r in range(WDim+1):\n",
    "        T = np.zeros(WDim)\n",
    "        T[r-1] = 1\n",
    "        te_output[str(r)] = trained.predict([T])[0] - trained.predict([np.zeros(WDim)])[0]\n",
    "#     te1 = trained.predict([[1,0]]) - trained.predict([[0,0]])\n",
    "#     te2 = trained.predict([[0,1]]) - trained.predict([[0,0]])    \n",
    "    return te_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2 = MLPRegressor(hidden_layer_sizes=(2,), max_iter = 2000, random_state=4227)\n",
    "nn10 = MLPRegressor(hidden_layer_sizes=(10,), max_iter = 2000, random_state=4227)\n",
    "ols = LinearRegression()\n",
    "rf1000 = RandomForestRegressor(n_estimators=1000)\n",
    "rf100 = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WDim_use = 5\n",
    "TE_use = [0.50]*(WDim_use+1)\n",
    "sim_range = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Data and simulate many OLS and other estimates\n",
    "dict_est = {}\n",
    "for w in range(WDim_use):\n",
    "    dict_est[str(w)] = {'OLS':[], 'NN2':[], 'NN10':[], 'RF1000':[], 'RF100':[]  }\n",
    "\n",
    "for r in range(sim_range):\n",
    "    df = sim_data(WDim=WDim_use, TE = TE_use, N = 1000)\n",
    "    # display(df.describe())\n",
    "    ols_HAT = ml_te(df,   WDim_use, ols)\n",
    "    nn2_HAT = ml_te(df,   WDim_use, nn2)\n",
    "    nn10_HAT = ml_te(df,  WDim_use, nn10)\n",
    "    rf1000_HAT = ml_te(df,WDim_use, rf1000)\n",
    "    rf100_HAT = ml_te(df, WDim_use, rf100)\n",
    "    for w in range(WDim_use):\n",
    "        dict_est[str(w)]['OLS'].append(ols_HAT[str(w)])\n",
    "        dict_est[str(w)]['NN2'].append(nn2_HAT[str(w)])\n",
    "        dict_est[str(w)]['NN10'].append(nn10_HAT[str(w)])\n",
    "        dict_est[str(w)]['RF1000'].append(rf1000_HAT[str(w)])\n",
    "        dict_est[str(w)]['RF100'].append(rf100_HAT[str(w)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Parameter 0\n",
      "OLS\n",
      " |Bias| of Est =   0.0 using OLS\n",
      "NN2\n",
      " |Bias| of Est =   0.5 using NN2\n",
      "NN10\n",
      " |Bias| of Est = 0.141 using NN10\n",
      "RF1000\n",
      " |Bias| of Est =   0.0 using RF1000\n",
      "RF100\n",
      " |Bias| of Est =   0.0 using RF100\n",
      "For Parameter 1\n",
      "OLS\n",
      " |Bias| of Est =   0.5 using OLS\n",
      "NN2\n",
      " |Bias| of Est = 0.502 using NN2\n",
      "NN10\n",
      " |Bias| of Est = 0.489 using NN10\n",
      "RF1000\n",
      " |Bias| of Est =   0.5 using RF1000\n",
      "RF100\n",
      " |Bias| of Est =   0.5 using RF100\n",
      "For Parameter 2\n",
      "OLS\n",
      " |Bias| of Est =   0.5 using OLS\n",
      "NN2\n",
      " |Bias| of Est = 0.587 using NN2\n",
      "NN10\n",
      " |Bias| of Est = 0.524 using NN10\n",
      "RF1000\n",
      " |Bias| of Est =   0.5 using RF1000\n",
      "RF100\n",
      " |Bias| of Est =   0.5 using RF100\n",
      "For Parameter 3\n",
      "OLS\n",
      " |Bias| of Est =   0.5 using OLS\n",
      "NN2\n",
      " |Bias| of Est = 0.412 using NN2\n",
      "NN10\n",
      " |Bias| of Est = 0.508 using NN10\n",
      "RF1000\n",
      " |Bias| of Est =   0.5 using RF1000\n",
      "RF100\n",
      " |Bias| of Est =   0.5 using RF100\n",
      "For Parameter 4\n",
      "OLS\n",
      " |Bias| of Est =   0.5 using OLS\n",
      "NN2\n",
      " |Bias| of Est = 0.568 using NN2\n",
      "NN10\n",
      " |Bias| of Est = 0.502 using NN10\n",
      "RF1000\n",
      " |Bias| of Est =   0.5 using RF1000\n",
      "RF100\n",
      " |Bias| of Est =   0.5 using RF100\n"
     ]
    }
   ],
   "source": [
    "for w in range(WDim_use):\n",
    "    print('For Parameter {0}'.format(w))\n",
    "    for a in ['OLS','NN2','NN10','RF1000','RF100']:\n",
    "        print(a)\n",
    "        est1_bias = np.abs( np.mean(dict_est[str(w)][a] ) - TE_use[w] )\n",
    "        print(' |Bias| of Est = {0:5.3} using {1}'.format(est1_bias, a))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Estimate 2')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(nrows=2,ncols=2, figsize=(15,8), sharex=True, sharey=True)\n",
    "ax[0,0].hist(dict_est['1']['OLS'],   bins=20, density=False,  label='ols',           alpha=0.25, color='coral')\n",
    "ax[0,0].hist(dict_est['1']['NN2'],   bins=20, density=False,  label='neural net 2',  alpha=0.25, color='darkgreen')\n",
    "# ax[0,0].hist(dict_est['1']['NN10'],  bins=20, density=False,  label='neural net 10', alpha=0.25, color='lime')\n",
    "# ax[0,0].hist(dict_est['1']['RF1000'],bins=20, density=False,  label='RF 1000',       alpha=0.25,  color='navy')\n",
    "ax[0,0].hist(dict_est['1']['RF100'], bins=20, density=False,  label='RF 100',        alpha=0.25,  color='skyblue')\n",
    "# ax[0,0].vlines(TE_use[0], 0, 10, colors='black', label='Truth')\n",
    "ax[0,0].legend()\n",
    "ax[0,0].grid()\n",
    "ax[0,0].set_title('Estimate 1')\n",
    "\n",
    "ax[1,0].hist(dict_est['1']['OLS'],   bins=20, density=False,  label='ols',           alpha=0.25, color='coral')\n",
    "# ax[1,0].hist(dict_est['1']['NN2'],   bins=20, density=False,  label='neural net 2',  alpha=0.25, color='darkgreen')\n",
    "ax[1,0].hist(dict_est['1']['NN10'],  bins=20, density=False,  label='neural net 10', alpha=0.25, color='lime')\n",
    "ax[1,0].hist(dict_est['1']['RF1000'],bins=20, density=False,  label='RF 1000',       alpha=0.25,  color='navy')\n",
    "# ax[1,0].hist(dict_est['1']['RF100'], bins=20, density=False,  label='RF 100',        alpha=0.25,  color='skyblue')\n",
    "# ax[1,0].vlines(TE_use[0], 0, 10, colors='black', label='Truth')\n",
    "ax[1,0].legend()\n",
    "ax[1,0].grid()\n",
    "ax[1,0].set_title('Estimate 1')\n",
    "\n",
    "ax[0,1].hist(dict_est['2']['OLS'],   bins=20, density=False, label='ols',           alpha=0.25, color='coral')\n",
    "ax[0,1].hist(dict_est['2']['NN2'],   bins=20, density=False, label='neural net 2',  alpha=0.25, color='darkgreen')\n",
    "# ax[0,1].hist(dict_est['2']['NN10'],  bins=20, density=False, label='neural net 10', alpha=0.25, color='lime')\n",
    "# ax[0,1].hist(dict_est['2']['RF1000'],bins=20, density=False, label='RF 1000',       alpha=0.25,  color='navy')\n",
    "ax[0,1].hist(dict_est['2']['RF100'], bins=20, density=False, label='RF 100',        alpha=0.25,  color='skyblue')\n",
    "# ax[0,1].vlines(TE_use[1], 0, 10, colors='black', label='Truth')\n",
    "ax[0,1].legend()\n",
    "ax[0,1].grid()\n",
    "ax[0,1].set_title('Estimate 2')\n",
    "\n",
    "ax[1,1].hist(dict_est['2']['OLS'],   bins=20, density=False, label='ols',           alpha=0.25, color='coral')\n",
    "# ax[1,1].hist(dict_est['2']['NN2'],   bins=20, density=False, label='neural net 2',  alpha=0.25, color='darkgreen')\n",
    "ax[1,1].hist(dict_est['2']['NN10'],  bins=20, density=False, label='neural net 10', alpha=0.25, color='lime')\n",
    "ax[1,1].hist(dict_est['2']['RF1000'],bins=20, density=False, label='RF 1000',       alpha=0.25,  color='navy')\n",
    "# ax[1,1].hist(dict_est['2']['RF100'], bins=20, density=False, label='RF 100',        alpha=0.25,  color='skyblue')\n",
    "# ax[1,1].vlines(TE_use[1], 0, 10, colors='black', label='Truth')\n",
    "ax[1,1].legend()\n",
    "ax[1,1].grid()\n",
    "ax[1,1].set_title('Estimate 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

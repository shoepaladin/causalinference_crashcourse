{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Inference Examples\n",
    "# 1 Foundations\n",
    "Julian Hsu\n",
    "Date Made: 5 Aug 2021 \n",
    "\n",
    "### Table of Contents with Navigation Links\n",
    "* [Write Causal Models](#Section1)\n",
    "* [Simulate Data](#Section2)\n",
    "* [Bootstrapping Examples](#Section3)\n",
    "* [Bootstrapping Examples - unconfoundedness violation](#Section4)\n",
    "* [Bootstrapping Examples - overlap violation](#Section5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsujulia/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/Users/hsujulia/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os \n",
    "\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.discrete.conditional_models import ConditionalLogit\n",
    "\n",
    "from IPython.display import display    \n",
    "\n",
    "\n",
    "import scipy.stats \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section1'></a>\n",
    "\n",
    "## Write Causal Models\n",
    "Write several functions here for estimate HTE. Each model _must_ do datasplitting.\n",
    "These functions will do a lot of predictions, so try to standardize the prediction models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stnomics as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section2'></a>\n",
    "\n",
    "## Bring in Simulated Data\n",
    "Pretend we've never seen this data before, and do balance checks between treatment and control \n",
    "\n",
    "For fun, use the Friedman function: https://www.sfu.ca/~ssurjano/fried.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    N = 2000\n",
    "    \n",
    "    cov = [[1.00, 0.08, 0.05, 0.05],\n",
    "           [0.08, 1.00,-0.08,-0.02],\n",
    "           [0.05,-0.08, 1.00,-0.10],\n",
    "           [0.05,-0.02,-0.10, 1.00]]\n",
    "    cov = np.eye(4)\n",
    "    X = np.random.multivariate_normal(np.zeros(4), cov,N)\n",
    "    x1,x2,x3,x4= X[:,0],X[:,1],X[:,2],X[:,3]\n",
    "\n",
    "    treatment_latent = 2*np.sin( np.pi * x4 * x3) + 10*(x2-0.5)**2 - 10*x1\n",
    "    m,s = np.average(treatment_latent), np.std(treatment_latent)\n",
    "\n",
    "    treatment_latent = (treatment_latent - m) / s\n",
    "    \n",
    "    random_t = np.random.normal(0,1,N)\n",
    "    \n",
    "    treatment_latent += random_t\n",
    "    \n",
    "    treatment = np.array( np.exp(treatment_latent) / (1+ np.exp(treatment_latent)) > np.random.uniform(0,1,N) ).astype(np.int32)\n",
    "\n",
    "#     Y = 100 +0.5*x1 - 6*x2 + -2*x4*x1 + 0.5*x1*x2 - 7*(x3+1)**(0.5) + 8/(0.5+x3+x4)\n",
    "    Y = 100 + 10*np.sin( np.pi * x1 * x2) + 20*(x3-0.5)**2 - 10*x4\n",
    "#     GT = np.std(Y)\n",
    "    random_y = np.random.normal(0,1,N)\n",
    "\n",
    "    GT = 5\n",
    "    Y += np.random.normal(1,2,N)\n",
    "    Y += GT*(treatment==1) \n",
    "    \n",
    "    df_est = pd.DataFrame({'x1':x1, 'x2':x2,'x3':x3,'x4':x4,'treatment':treatment, 'Y':Y, 'GT':GT} )\n",
    "    df_est['x1_2'] = df_est['x1'].pow(2)\n",
    "    df_est['x2_2'] = df_est['x2'].pow(2)\n",
    "    df_est['x3_2'] = df_est['x3'].pow(2)\n",
    "    df_est['x4_2'] = df_est['x4'].pow(2)    \n",
    "    return df_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>treatment</th>\n",
       "      <th>Y</th>\n",
       "      <th>GT</th>\n",
       "      <th>x1_2</th>\n",
       "      <th>x2_2</th>\n",
       "      <th>x3_2</th>\n",
       "      <th>x4_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.302836</td>\n",
       "      <td>-0.273219</td>\n",
       "      <td>-0.281879</td>\n",
       "      <td>0.553477</td>\n",
       "      <td>0</td>\n",
       "      <td>103.102604</td>\n",
       "      <td>5</td>\n",
       "      <td>0.091710</td>\n",
       "      <td>0.074648</td>\n",
       "      <td>0.079456</td>\n",
       "      <td>0.306337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.798644</td>\n",
       "      <td>-0.444715</td>\n",
       "      <td>-1.171075</td>\n",
       "      <td>-0.230991</td>\n",
       "      <td>0</td>\n",
       "      <td>168.355165</td>\n",
       "      <td>5</td>\n",
       "      <td>0.637832</td>\n",
       "      <td>0.197771</td>\n",
       "      <td>1.371416</td>\n",
       "      <td>0.053357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.621863</td>\n",
       "      <td>-0.404925</td>\n",
       "      <td>-0.453191</td>\n",
       "      <td>0.384109</td>\n",
       "      <td>1</td>\n",
       "      <td>127.531503</td>\n",
       "      <td>5</td>\n",
       "      <td>0.386714</td>\n",
       "      <td>0.163965</td>\n",
       "      <td>0.205382</td>\n",
       "      <td>0.147540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.591051</td>\n",
       "      <td>-0.710777</td>\n",
       "      <td>0.232697</td>\n",
       "      <td>-0.516163</td>\n",
       "      <td>0</td>\n",
       "      <td>115.601906</td>\n",
       "      <td>5</td>\n",
       "      <td>0.349341</td>\n",
       "      <td>0.505205</td>\n",
       "      <td>0.054148</td>\n",
       "      <td>0.266424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.230823</td>\n",
       "      <td>-1.091950</td>\n",
       "      <td>0.098173</td>\n",
       "      <td>-0.823250</td>\n",
       "      <td>1</td>\n",
       "      <td>110.665102</td>\n",
       "      <td>5</td>\n",
       "      <td>1.514925</td>\n",
       "      <td>1.192355</td>\n",
       "      <td>0.009638</td>\n",
       "      <td>0.677740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.958651</td>\n",
       "      <td>-1.182807</td>\n",
       "      <td>0.539264</td>\n",
       "      <td>-0.993485</td>\n",
       "      <td>0</td>\n",
       "      <td>113.992964</td>\n",
       "      <td>5</td>\n",
       "      <td>0.919011</td>\n",
       "      <td>1.399032</td>\n",
       "      <td>0.290805</td>\n",
       "      <td>0.987012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.502396</td>\n",
       "      <td>1.269370</td>\n",
       "      <td>0.653832</td>\n",
       "      <td>-0.427190</td>\n",
       "      <td>1</td>\n",
       "      <td>121.649704</td>\n",
       "      <td>5</td>\n",
       "      <td>0.252402</td>\n",
       "      <td>1.611300</td>\n",
       "      <td>0.427496</td>\n",
       "      <td>0.182491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.511341</td>\n",
       "      <td>-0.708102</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>1.215416</td>\n",
       "      <td>1</td>\n",
       "      <td>81.581522</td>\n",
       "      <td>5</td>\n",
       "      <td>0.261470</td>\n",
       "      <td>0.501409</td>\n",
       "      <td>0.382218</td>\n",
       "      <td>1.477237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.781418</td>\n",
       "      <td>0.874056</td>\n",
       "      <td>-0.537727</td>\n",
       "      <td>1.205602</td>\n",
       "      <td>0</td>\n",
       "      <td>119.279825</td>\n",
       "      <td>5</td>\n",
       "      <td>0.610614</td>\n",
       "      <td>0.763975</td>\n",
       "      <td>0.289150</td>\n",
       "      <td>1.453477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.508562</td>\n",
       "      <td>1.572544</td>\n",
       "      <td>-0.849714</td>\n",
       "      <td>-0.772866</td>\n",
       "      <td>1</td>\n",
       "      <td>157.387855</td>\n",
       "      <td>5</td>\n",
       "      <td>0.258635</td>\n",
       "      <td>2.472894</td>\n",
       "      <td>0.722015</td>\n",
       "      <td>0.597321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2        x3        x4  treatment           Y  GT  \\\n",
       "0     0.302836 -0.273219 -0.281879  0.553477          0  103.102604   5   \n",
       "1    -0.798644 -0.444715 -1.171075 -0.230991          0  168.355165   5   \n",
       "2    -0.621863 -0.404925 -0.453191  0.384109          1  127.531503   5   \n",
       "3    -0.591051 -0.710777  0.232697 -0.516163          0  115.601906   5   \n",
       "4    -1.230823 -1.091950  0.098173 -0.823250          1  110.665102   5   \n",
       "...        ...       ...       ...       ...        ...         ...  ..   \n",
       "1995  0.958651 -1.182807  0.539264 -0.993485          0  113.992964   5   \n",
       "1996  0.502396  1.269370  0.653832 -0.427190          1  121.649704   5   \n",
       "1997  0.511341 -0.708102  0.618238  1.215416          1   81.581522   5   \n",
       "1998  0.781418  0.874056 -0.537727  1.205602          0  119.279825   5   \n",
       "1999  0.508562  1.572544 -0.849714 -0.772866          1  157.387855   5   \n",
       "\n",
       "          x1_2      x2_2      x3_2      x4_2  \n",
       "0     0.091710  0.074648  0.079456  0.306337  \n",
       "1     0.637832  0.197771  1.371416  0.053357  \n",
       "2     0.386714  0.163965  0.205382  0.147540  \n",
       "3     0.349341  0.505205  0.054148  0.266424  \n",
       "4     1.514925  1.192355  0.009638  0.677740  \n",
       "...        ...       ...       ...       ...  \n",
       "1995  0.919011  1.399032  0.290805  0.987012  \n",
       "1996  0.252402  1.611300  0.427496  0.182491  \n",
       "1997  0.261470  0.501409  0.382218  1.477237  \n",
       "1998  0.610614  0.763975  0.289150  1.453477  \n",
       "1999  0.258635  2.472894  0.722015  0.597321  \n",
       "\n",
       "[2000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_max_iter = 500\n",
    "## treatment prediction models\n",
    "t_models = {}\n",
    "t_models['LogitCV'] = LogisticRegressionCV(cv=5, random_state=27, n_jobs=-1)\n",
    "t_models['logit'] = LogisticRegression(penalty='l2',solver='lbfgs', C=1, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L1_C2'] = LogisticRegression(penalty='l1',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['logit_L2_C5'] = LogisticRegression(penalty='l2',C=2, max_iter=model_max_iter, fit_intercept=True)\n",
    "t_models['rf_md10'] = RandomForestClassifier(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "t_models['rf_md3'] = RandomForestClassifier(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "t_models['nn'] = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1,max_iter=model_max_iter)\n",
    "## outcome prediction models\n",
    "y_models = {}\n",
    "y_models['LassoCV'] = LassoCV(cv=5, n_jobs=-1,  random_state=27)\n",
    "y_models['ols'] = LinearRegression()\n",
    "y_models['lasso_a2'] = Lasso(alpha=2,max_iter=model_max_iter)\n",
    "y_models['ridge_a2'] = Ridge(alpha=2,max_iter=model_max_iter)\n",
    "y_models['rf_md10'] = RandomForestRegressor(n_estimators=25,max_depth=10, min_samples_split=200,n_jobs=-1)\n",
    "y_models['rf_md3'] = RandomForestRegressor(n_estimators=25,max_depth=3, min_samples_split=200,n_jobs=-1)\n",
    "y_models['nn'] = MLPRegressor(alpha=1e-5, hidden_layer_sizes=(3, 2), random_state=1, max_iter=model_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data_splits = 4\n",
    "aux_dictionary = {'n_bins': 2, 'n_trees':2, 'max_depth':2, \n",
    "                  'upper':0.999, 'lower':0.001,\n",
    "                  'bootstrapreps':100,\n",
    "                  'subsample_ratio':0.5}\n",
    "bootstrap_number = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsujulia/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m feature_list \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m      5\u001b[0m ols \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mate\u001b[38;5;241m.\u001b[39mols_vanilla(df, \n\u001b[1;32m      6\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplits\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_list, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                 y_models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLassoCV\u001b[39m\u001b[38;5;124m'\u001b[39m],t_models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitCV\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m                n_data_splits, aux_dictionary )\n\u001b[0;32m----> 9\u001b[0m pbin \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropbinning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msplits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtreatment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43my_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLassoCV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLogitCV\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m               \u001b[49m\u001b[43mn_data_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux_dictionary\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m plm \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mate\u001b[38;5;241m.\u001b[39mdml\u001b[38;5;241m.\u001b[39mdml_plm(df, \n\u001b[1;32m     14\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplits\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_list, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                 y_models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLassoCV\u001b[39m\u001b[38;5;124m'\u001b[39m],t_models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitCV\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     16\u001b[0m                n_data_splits, aux_dictionary )\n\u001b[1;32m     17\u001b[0m irm \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mate\u001b[38;5;241m.\u001b[39mdml\u001b[38;5;241m.\u001b[39mdml_irm(df, \n\u001b[1;32m     18\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msplits\u001b[39m\u001b[38;5;124m'\u001b[39m, feature_list, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m                 y_models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLassoCV\u001b[39m\u001b[38;5;124m'\u001b[39m],t_models[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitCV\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     20\u001b[0m                n_data_splits, aux_dictionary )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stnomics.py:614\u001b[0m, in \u001b[0;36mate.propbinning\u001b[0;34m(data_est, split_name, feature_name, outcome_name, treatment_name, ymodel, tmodel, n_data_splits, aux_dictionary)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpropbinning\u001b[39m(data_est, \n\u001b[1;32m    605\u001b[0m                 split_name, feature_name, outcome_name, treatment_name,\n\u001b[1;32m    606\u001b[0m                 ymodel,tmodel,\n\u001b[1;32m    607\u001b[0m                n_data_splits,\n\u001b[1;32m    608\u001b[0m                aux_dictionary):\n\u001b[1;32m    609\u001b[0m     main_result \u001b[38;5;241m=\u001b[39m ate\u001b[38;5;241m.\u001b[39mpropbinning_main(data_est, \n\u001b[1;32m    610\u001b[0m                 split_name, feature_name, outcome_name, treatment_name,\n\u001b[1;32m    611\u001b[0m                 ymodel,tmodel,\n\u001b[1;32m    612\u001b[0m                n_data_splits,\n\u001b[1;32m    613\u001b[0m                aux_dictionary)\n\u001b[0;32m--> 614\u001b[0m     pbin_bt_results \u001b[38;5;241m=\u001b[39m \u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo_reps\u001b[49m\u001b[43m(\u001b[49m\u001b[43maux_dictionary\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbootstrapreps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropbinning_main\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msplit_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutcome_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreatment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mymodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mn_data_splits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m                   \u001b[49m\u001b[43maux_dictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATE TE\u001b[39m\u001b[38;5;124m'\u001b[39m:pbin_bt_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATE mean\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATE SE\u001b[39m\u001b[38;5;124m'\u001b[39m: pbin_bt_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATE std\u001b[39m\u001b[38;5;124m'\u001b[39m],            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATT TE\u001b[39m\u001b[38;5;124m'\u001b[39m:pbin_bt_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATT mean\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATT SE\u001b[39m\u001b[38;5;124m'\u001b[39m: pbin_bt_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATT std\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPScore\u001b[39m\u001b[38;5;124m'\u001b[39m:main_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPScore\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stnomics.py:350\u001b[0m, in \u001b[0;36mbootstrap.go_reps\u001b[0;34m(bootstrapreps, est_model, *args)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgo_reps\u001b[39m(bootstrapreps, est_model, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 350\u001b[0m     reps_output \u001b[38;5;241m=\u001b[39m \u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbootstrapreps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     ate_te \u001b[38;5;241m=\u001b[39m bootstrap\u001b[38;5;241m.\u001b[39mresults(reps_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    352\u001b[0m     ate_se \u001b[38;5;241m=\u001b[39m bootstrap\u001b[38;5;241m.\u001b[39mresults(reps_output[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stnomics.py:338\u001b[0m, in \u001b[0;36mbootstrap.reps\u001b[0;34m(bootstrapreps, est_model, *args)\u001b[0m\n\u001b[1;32m    334\u001b[0m bt_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m0\u001b[39m]), \n\u001b[1;32m    335\u001b[0m                             \u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    336\u001b[0m                             replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    337\u001b[0m df_bt \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[bt_index]        \n\u001b[0;32m--> 338\u001b[0m est \u001b[38;5;241m=\u001b[39m \u001b[43mest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_bt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m         \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m ate_est\u001b[38;5;241m.\u001b[39mappend(est[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATE TE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    341\u001b[0m ate_se\u001b[38;5;241m.\u001b[39mappend(est[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mATE SE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/stnomics.py:657\u001b[0m, in \u001b[0;36mate.propbinning_main\u001b[0;34m(data_est, split_name, feature_name, outcome_name, treatment_name, ymodel, tmodel, n_data_splits, aux_dictionary)\u001b[0m\n\u001b[1;32m    654\u001b[0m yhat_treat\u001b[38;5;241m.\u001b[39mextend(tpred)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m## Predict counterfactual outcomes for control\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m ols_control\u001b[38;5;241m=\u001b[39m\u001b[43mymodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_est\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_control\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_est\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutcome_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbin_control\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m    658\u001b[0m cpred \u001b[38;5;241m=\u001b[39m ols_control\u001b[38;5;241m.\u001b[39mpredict(data_est[feature_name][(test\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)])\n\u001b[1;32m    659\u001b[0m yhat_control\u001b[38;5;241m.\u001b[39mextend(cpred)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1669\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;66;03m# We do a double for loop folded in one, in order to be able to\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;66;03m# iterate in parallel on l1_ratio and folds\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m jobs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1651\u001b[0m     delayed(_path_residuals)(\n\u001b[1;32m   1652\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1667\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m folds\n\u001b[1;32m   1668\u001b[0m )\n\u001b[0;32m-> 1669\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1674\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(mse_paths, (n_l1_ratio, \u001b[38;5;28mlen\u001b[39m(folds), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;66;03m# The mean is computed over folds.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1054\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1054\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:933\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 933\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py:574\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 574\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = generate_data()\n",
    "\n",
    "feature_list = [x for x in df.columns if 'x' in x]\n",
    "\n",
    "ols = st.ate.ols_vanilla(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "pbin = st.ate.propbinning(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "plm = st.ate.dml.dml_plm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "irm = st.ate.dml.dml_irm(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data()\n",
    "df['splits'] = np.random.choice(n_data_splits, len(df), replace=True)\n",
    "df = df.sort_values(by='splits')    \n",
    "\n",
    "## Predict Treatment\n",
    "that = st.predict_treatment_indicator(df, 'splits', n_data_splits, feature_list,'treatment',t_models['LogitCV'])\n",
    "df['that'] = that\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "ax.hist(df.loc[df.treatment==1]['that'], density=False, facecolor='g', alpha=0.25)\n",
    "ax.hist(df.loc[df.treatment==0]['that'], density=False, facecolor='b', alpha=0.25)\n",
    "control_range_to_remove = np.percentile(df.loc[df.treatment==1]['that'], q= 50) , np.percentile(df.loc[df.treatment==1]['that'], q= 99)\n",
    "print(control_range_to_remove)\n",
    "\n",
    "df = df.loc[ (df.treatment==1) | ( (df.that.between(control_range_to_remove[0],control_range_to_remove[1])==False) & (df.treatment==0) )   ]\n",
    "fig,ax = plt.subplots(nrows=1,ncols=1, figsize=(9,3), sharex=True, sharey=True)\n",
    "ax.hist(df.loc[df.treatment==1]['that'], density=False, facecolor='g', alpha=0.25)\n",
    "ax.hist(df.loc[df.treatment==0]['that'], density=False, facecolor='b', alpha=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section4'></a>\n",
    "\n",
    "## Bootstrapping\n",
    "* Bootstrap results using random datasets when all three assumptions are satisfied.\n",
    "* Bootstrap results when the unconfoundedness assumption is violated. Do this by removing one fot the features from training.\n",
    "* Bootstrap results when the overlap assumption is violated. Do this by removing control observations with propensities near the median treatment obervation propensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_x = []\n",
    "pbin_x= []\n",
    "plm_x = []\n",
    "irm_x = []\n",
    "ipw_x = []\n",
    "\n",
    "ols_x_unconf = []\n",
    "pbin_x_unconf= []\n",
    "plm_x_unconf = []\n",
    "irm_x_unconf = []\n",
    "ipw_x_unconf = []\n",
    "\n",
    "ols_x_overlap = []\n",
    "pbin_x_overlap= []\n",
    "plm_x_overlap = []\n",
    "irm_x_overlap = []\n",
    "ipw_x_overlap = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(bootstrap_number):\n",
    "    df = generate_data()\n",
    "    \n",
    "    feature_list = [x for x in df.columns if 'x' in x]\n",
    "    \n",
    "    feature_list_ab = [x for x in feature_list if '3' not in x and '4' not in x]\n",
    "    \n",
    "    ## Regular \n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "    ols_x.append(ols['ATE TE'])\n",
    "    pbin_x.append(pbin['ATE TE'])\n",
    "    plm_x.append(plm['ATE TE'])\n",
    "    irm_x.append(irm['ATE TE'])    \n",
    "    ipw_x.append(ip['ATE TE'])   \n",
    "    \n",
    "    ## When unconfoundedness assumption is not true\n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list_ab, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "    ols_x_unconf.append(ols['ATE TE'])\n",
    "    pbin_x_unconf.append(pbin['ATE TE'])\n",
    "    plm_x_unconf.append(plm['ATE TE'])\n",
    "    irm_x_unconf.append(irm['ATE TE'])    \n",
    "    ipw_x_unconf.append(ip['ATE TE'])        \n",
    "\n",
    "\n",
    "    ## When overlap condition is not true\n",
    "    df['splits'] = np.random.choice(n_data_splits, len(df), replace=True)\n",
    "    df = df.sort_values(by='splits')    \n",
    "    ## Predict Treatment\n",
    "    that = st.predict_treatment_indicator(df, 'splits', n_data_splits, feature_list,'treatment',t_models['LogitCV'])\n",
    "    df['that'] = that    \n",
    "    control_range_to_remove = np.percentile(df.loc[df.treatment==1]['that'], q= 50) , np.percentile(df.loc[df.treatment==1]['that'], q= 99)\n",
    "    df = df.loc[ (df.treatment==1) | ( (df.that.between(control_range_to_remove[0],control_range_to_remove[1])==False) & (df.treatment==0) )   ]\n",
    "\n",
    "\n",
    "    ols = st.ate.ols_vanilla(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    pbin = st.ate.propbinning(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    plm = st.ate.dml.dml_plm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    irm = st.ate.dml.dml_irm(df, \n",
    "                    'splits', feature_list, 'Y', 'treatment',\n",
    "                    y_models['LassoCV'],t_models['LogitCV'],\n",
    "                   n_data_splits, aux_dictionary )\n",
    "    ip = st.ate.ipw(df, \n",
    "                'splits', feature_list, 'Y', 'treatment',\n",
    "                y_models['LassoCV'],t_models['LogitCV'],\n",
    "               n_data_splits, aux_dictionary )\n",
    "\n",
    "    ols_x_overlap.append(ols['ATE TE'])\n",
    "    pbin_x_overlap.append(pbin['ATE TE'])\n",
    "    plm_x_overlap.append(plm['ATE TE'])\n",
    "    irm_x_overlap.append(irm['ATE TE'])    \n",
    "    ipw_x_overlap.append(ip['ATE TE'])        \n",
    "\n",
    "ols_x = np.array(ols_x) - 5\n",
    "pbin_x = np.array(pbin_x) - 5\n",
    "plm_x = np.array(plm_x) - 5\n",
    "irm_x = np.array(irm_x) - 5\n",
    "ipw_x = np.array(ipw_x) - 5\n",
    "\n",
    "ols_x_unconf = np.array(ols_x_unconf) - 5\n",
    "pbin_x_unconf = np.array(pbin_x_unconf) - 5\n",
    "plm_x_unconf = np.array(plm_x_unconf) - 5\n",
    "irm_x_unconf = np.array(irm_x_unconf) - 5\n",
    "ipw_x_unconf = np.array(ipw_x_unconf) - 5    \n",
    "\n",
    "ols_x_overlap = np.array(ols_x_overlap) - 5\n",
    "pbin_x_overlap = np.array(pbin_x_overlap) - 5\n",
    "plm_x_overlap = np.array(plm_x_overlap) - 5\n",
    "irm_x_overlap = np.array(irm_x_overlap) - 5\n",
    "ipw_x_overlap = np.array(ipw_x_overlap) - 5    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_avg_med_iqr(x):\n",
    "    avg = np.average(x)\n",
    "    p50 = np.percentile(x, 50)\n",
    "    p25 = np.percentile(x, 25)\n",
    "    p75 = np.percentile(x, 75)    \n",
    "    print('AVG: {0:5.2f}   MED: {1:5.2f}   IQR: [{2:5.3f}, {3:5.2f}]'.format(avg, p50, p25, p75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bias when all assumptions are met')\n",
    "print_avg_med_iqr(ols_x)    \n",
    "print_avg_med_iqr(pbin_x)    \n",
    "print_avg_med_iqr(plm_x)    \n",
    "print_avg_med_iqr(irm_x)    \n",
    "print_avg_med_iqr(ipw_x)    \n",
    "\n",
    "print('')\n",
    "print('Bias when unconfoundedness is not met')\n",
    "print_avg_med_iqr(ols_x_unconf) \n",
    "print_avg_med_iqr(pbin_x_unconf)    \n",
    "print_avg_med_iqr(plm_x_unconf)    \n",
    "print_avg_med_iqr(irm_x_unconf)    \n",
    "print_avg_med_iqr(ipw_x_unconf)    \n",
    "\n",
    "print('')\n",
    "print('Bias when overlap is not met')\n",
    "print_avg_med_iqr(ols_x_overlap)    \n",
    "print_avg_med_iqr(pbin_x_overlap)    \n",
    "print_avg_med_iqr(plm_x_overlap)    \n",
    "print_avg_med_iqr(irm_x_overlap)    \n",
    "print_avg_med_iqr(ipw_x_overlap[~np.isnan(ipw_x_overlap)])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section5'></a>\n",
    "\n",
    "## Prediction vs Causal\n",
    "Let's compare the estimated treatment effects $\\hat{Y}(W=1) - \\hat{Y}(W=0) $ among ML models. Let's use the treatment effect of multiple features.\n",
    "\n",
    "We expect to find evidence of regularization bias. As demonstrated in **Figure 1** of Chernozhukov et al., \"*Double/Debiased Machine Learning for Treatment and Structural Parameters*\" (https://arxiv.org/pdf/1608.00060.pdf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_data(WDim=2,\n",
    "             TE = [1,1],\n",
    "             K = 4,\n",
    "             N = 50):\n",
    "    corr = True\n",
    "    if corr==False:\n",
    "        pass\n",
    "    else:\n",
    "        x = np.random.uniform(0,1,N)\n",
    "        \n",
    "    for r in range(WDim+1):\n",
    "        if corr==False:\n",
    "            W = np.random.randint(0,2, N)     \n",
    "        else: \n",
    "            x = np.random.uniform(-1,1,(N,K))\n",
    "            xdot = np.dot(  x, np.random.uniform(-1,1, K) )\n",
    "            W = ( ( np.exp(xdot ) / (1+ np.exp(xdot)) ) > np.random.uniform(0.45,0.55) ).astype(float)\n",
    "        if r ==0:\n",
    "            Y = TE[r]*W + np.dot(  x, np.random.uniform(-1,1, K) ) + np.random.normal(0,1, N)\n",
    "            data_dict = {'W1':W}\n",
    "        else:\n",
    "            Y += TE[r]*W \n",
    "            data_dict['W'+str(r)] = W\n",
    "    data_dict['Y'] = Y\n",
    "    for k in range(K):\n",
    "        data_dict['x'+str(k)] = x[:,k]\n",
    "    return pd.DataFrame(data=data_dict, index=np.arange(N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = np.concatenate( [np.zeros(WDim_use),\n",
    "    np.array([df[r].mean() for r in df.columns if 'x' in r ]) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , -0.01363433, -0.00242964])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_te(X, WDim, func):\n",
    "    xx = X[[x for x in X.columns if 'W' in x]+\\\n",
    "                         [x for x in X.columns if 'x' in x]]\n",
    "    trained = func.fit(xx, X['Y'])\n",
    "    te_output = {}\n",
    "    \n",
    "    ## Estimate the ATE by taking the average of the sample\n",
    "    xc = xx.copy()\n",
    "    for l in [o for o in xx.columns if 'W' in o]:\n",
    "        xc[l] = 0        \n",
    "    \n",
    "    for r in range(1,WDim+1):\n",
    "        ## Estimate the ATE by making a copy of the dataset\n",
    "        xt = xx.copy()\n",
    "        xt['W'+str(r)] = 1\n",
    "        for l in [o for o in xx.columns if 'W' in o and 'W'+str(r)!=o]:\n",
    "            xt[l] = 0\n",
    "        te_output[str(r)] = trained.predict(xt).mean() - trained.predict(xc).mean()\n",
    "    return te_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2 = MLPRegressor(hidden_layer_sizes=(2,), max_iter = 2000, random_state=4227)\n",
    "nn10 = MLPRegressor(hidden_layer_sizes=(10,), max_iter = 2000, random_state=4227)\n",
    "ols = LinearRegression()\n",
    "rf1000 = RandomForestRegressor(n_estimators=1000)\n",
    "rf100 = RandomForestRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "WDim_use = 3\n",
    "TE_use = [0.50]*(WDim_use+1)\n",
    "sim_range = 500\n",
    "sim_range = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Data and simulate many OLS and other estimates\n",
    "dict_est = {}\n",
    "for w in range(1,WDim_use+1):\n",
    "    dict_est[str(w)] = {'OLS':[], 'NN2':[], 'NN10':[], 'RF1000':[], 'RF100':[]  }\n",
    "\n",
    "for r in range(sim_range):\n",
    "    df = sim_data(WDim=WDim_use, TE = TE_use, K=2, N = 1000)\n",
    "    # display(df.describe())\n",
    "    ols_HAT = ml_te(df,   WDim_use, ols)\n",
    "    nn2_HAT = ml_te(df,   WDim_use, nn2)\n",
    "    nn10_HAT = ml_te(df,  WDim_use, nn10)\n",
    "#     rf1000_HAT = ml_te(df,WDim_use, rf1000)\n",
    "#     rf100_HAT = ml_te(df, WDim_use, rf100)\n",
    "    for w in range(1,WDim_use+1):\n",
    "        dict_est[str(w)]['OLS'].append(ols_HAT[str(w)])\n",
    "        dict_est[str(w)]['NN2'].append(nn2_HAT[str(w)])\n",
    "        dict_est[str(w)]['NN10'].append(nn10_HAT[str(w)])\n",
    "#         dict_est[str(w)]['RF1000'].append(rf1000_HAT[str(w)])\n",
    "#         dict_est[str(w)]['RF100'].append(rf100_HAT[str(w)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Parameter 1\n",
      "OLS\n",
      " |Bias| of Est = 0.0174 using OLS\n",
      "NN2\n",
      " |Bias| of Est = 0.266 using NN2\n",
      "NN10\n",
      " |Bias| of Est = 0.0643 using NN10\n",
      "For Parameter 2\n",
      "OLS\n",
      " |Bias| of Est = 0.0124 using OLS\n",
      "NN2\n",
      " |Bias| of Est = 0.286 using NN2\n",
      "NN10\n",
      " |Bias| of Est = 0.0458 using NN10\n",
      "For Parameter 3\n",
      "OLS\n",
      " |Bias| of Est = 0.0527 using OLS\n",
      "NN2\n",
      " |Bias| of Est = 0.164 using NN2\n",
      "NN10\n",
      " |Bias| of Est = 0.178 using NN10\n"
     ]
    }
   ],
   "source": [
    "for w in range(1,WDim_use+1):\n",
    "    print('For Parameter {0}'.format(w))\n",
    "#     for a in ['OLS','NN2','NN10','RF1000','RF100']:\n",
    "    for a in ['OLS','NN2','NN10']:        \n",
    "        print(a)\n",
    "        est1_bias = np.abs( np.mean(dict_est[str(w)][a] ) - TE_use[w] )\n",
    "        print(' |Bias| of Est = {0:5.3} using {1}'.format(est1_bias, a))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Estimate 2')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(nrows=2,ncols=2, figsize=(15,8), sharex=True, sharey=True)\n",
    "ax[0,0].hist(dict_est['1']['OLS'],   bins=20, density=False,  label='ols',           alpha=0.45, color='royalblue')\n",
    "ax[0,0].hist(dict_est['1']['NN2'],   bins=20, density=False,  label='neural net 2',  alpha=0.45, color='darkgreen')\n",
    "ax[0,0].hist(dict_est['1']['NN10'],  bins=20, density=False,  label='neural net 10', alpha=0.45, color='orchid')\n",
    "# ax[0,0].hist(dict_est['1']['RF1000'],bins=20, density=False,  label='RF 1000',       alpha=0.45,  color='navy')\n",
    "# ax[0,0].hist(dict_est['1']['RF100'], bins=20, density=False,  label='RF 100',        alpha=0.45,  color='skyblue')\n",
    "ax[0,0].vlines(TE_use[0], 0, 10, colors='black', label='Truth')\n",
    "ax[0,0].legend()\n",
    "ax[0,0].grid()\n",
    "ax[0,0].set_title('Estimate 1')\n",
    "\n",
    "ax[1,0].hist(dict_est['1']['OLS'],   bins=20, density=False,  label='ols',           alpha=0.45, color='royalblue')\n",
    "ax[1,0].hist(dict_est['1']['NN2'],   bins=20, density=False,  label='neural net 2',  alpha=0.45, color='darkgreen')\n",
    "ax[1,0].hist(dict_est['1']['NN10'],  bins=20, density=False,  label='neural net 10', alpha=0.45, color='orchid')\n",
    "# ax[1,0].hist(dict_est['1']['RF1000'],bins=20, density=False,  label='RF 1000',       alpha=0.45,  color='navy')\n",
    "# ax[1,0].hist(dict_est['1']['RF100'], bins=20, density=False,  label='RF 100',        alpha=0.45,  color='skyblue')\n",
    "ax[1,0].vlines(TE_use[0], 0, 10, colors='black', label='Truth')\n",
    "ax[1,0].legend()\n",
    "ax[1,0].grid()\n",
    "ax[1,0].set_title('Estimate 1')\n",
    "\n",
    "ax[0,1].hist(dict_est['2']['OLS'],   bins=20, density=False, label='ols',           alpha=0.45, color='royalblue')\n",
    "ax[0,1].hist(dict_est['2']['NN2'],   bins=20, density=False, label='neural net 2',  alpha=0.45, color='darkgreen')\n",
    "ax[0,1].hist(dict_est['2']['NN10'],  bins=20, density=False, label='neural net 10', alpha=0.45, color='orchid')\n",
    "# ax[0,1].hist(dict_est['2']['RF1000'],bins=20, density=False, label='RF 1000',       alpha=0.45,  color='navy')\n",
    "# ax[0,1].hist(dict_est['2']['RF100'], bins=20, density=False, label='RF 100',        alpha=0.45,  color='skyblue')\n",
    "ax[0,1].vlines(TE_use[1], 0, 10, colors='black', label='Truth')\n",
    "ax[0,1].legend()\n",
    "ax[0,1].grid()\n",
    "ax[0,1].set_title('Estimate 2')\n",
    "\n",
    "ax[1,1].hist(dict_est['2']['OLS'],   bins=20, density=False, label='ols',           alpha=0.45, color='royalblue')\n",
    "ax[1,1].hist(dict_est['2']['NN2'],   bins=20, density=False, label='neural net 2',  alpha=0.45, color='darkgreen')\n",
    "ax[1,1].hist(dict_est['2']['NN10'],  bins=20, density=False, label='neural net 10', alpha=0.45, color='orchid')\n",
    "# ax[1,1].hist(dict_est['2']['RF1000'],bins=20, density=False, label='RF 1000',       alpha=0.45,  color='navy')\n",
    "# ax[1,1].hist(dict_est['2']['RF100'], bins=20, density=False, label='RF 100',        alpha=0.45,  color='skyblue')\n",
    "ax[1,1].vlines(TE_use[1], 0, 10, colors='black', label='Truth')\n",
    "ax[1,1].legend()\n",
    "ax[1,1].grid()\n",
    "ax[1,1].set_title('Estimate 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
